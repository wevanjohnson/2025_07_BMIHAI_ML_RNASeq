tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
train_rf_2 <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
library(randomForest)
train_rf_2 <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svmfit.test <- svm(test.labels ~ ., data = test.plus.label, kernel = "linear", cost = 10, scale = FALSE)
## SVM
svmfit.test <- svm(test.labels ~ ., data = test.plus.labels, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit.test, test.plus.label[,-1], type = "class"))
svmfit.test <- svm(test.labels ~ ., data = test.plus.labels, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit.test, test.plus.label[,-1], type = "class"))
svmfit.test <- svm(test.labels ~ ., data = test.plus.labels, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit.test, test.plus.label[,-1], type = "class"))
predict(svmfit.test, test.plus.label[,-1], type = "class")
y_hat <- as.factor(predict(svmfit.test, test.plus.labels[,-1], type = "class"))
confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(test.labels ~ ., method = "rf", data = test.plus.labels,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(test.labels ~ ., method = "rf", data = test.plus.labels,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf.test <- randomForest(test.labels ~ ., data = test.plus.labels,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, test.plus.label[,-1], type = "class"))
rf.test <- randomForest(test.labels ~ ., data = test.plus.labels,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf.test, test.plus.label[,-1], type = "class"))
predict(rf.test, test.plus.label[,-1], type = "class")
y_hat <- as.factor(predict(rf.test, test.plus.labels[,-1], type = "class"))
confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:50],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:50],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
predict(cvfit, test, s = "lambda.min", type = "class")
## using the most signifcant 500 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:50],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## svm
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:50],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
### SVM
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
## Elastic Net
library(glmnet)
library(caret)
## using the most signifcant 500 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:500],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## svm
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:500],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
### SVM
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
### Random Forest
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
pca_out <- prcomp(t(assay(indata,"log_combat_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
pca_plot %>% ggplot(aes(x=PC1, y=PC2, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
set.seed(1)
umap_out <- umap(t(assay(indata,"log_combat_cpm")))
umap_plot <- data.frame(umap_out$layout, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
umap_plot %>% ggplot(aes(x=X1, y=X2, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
pca_out
pca_out$sdev
pca_out$sdev/sum(pca_out$sdev)
pca_out$sdev^2/sum(pca_out$sdev^2)
plot(pca_out$sdev^2/sum(pca_out$sdev^2))
plot(cumsum(pca_out$sdev^2/sum(pca_out$sdev^2)))
cumsum(pca_out$sdev^2/sum(pca_out$sdev^2))
dim(indata)
umap_out <- umap(t(assay(indata,"log_combat_cpm")))
umap_plot <- data.frame(umap_out$layout, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
umap_plot %>% ggplot(aes(x=X1, y=X2, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
pca_out <- prcomp(t(assay(indata,"log_combat_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
pca_plot %>% ggplot(aes(x=PC1, y=PC2, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
pca_plot %>% ggplot(aes(x=PC1, y=PC3, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
set.seed(1)
umap_out <- umap(t(assay(indata,"log_combat_cpm")))
umap_plot <- data.frame(umap_out$layout, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
umap_plot %>% ggplot(aes(x=X1, y=X2, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
table(colData(indata)[,2:4])
pca_out <- prcomp(t(assay(indata,"log_cpm")))
assays(indata)
pca_out <- prcomp(t(assay(indata,"log_counts_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2)
pca_plot %>% ggplot(aes(x=PC1, y=PC3, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
pca_out <- prcomp(t(assay(indata,"log_counts_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2,
Batch=indata$batch)
pca_plot %>% ggplot(aes(x=PC1, y=PC3, color=Batch, shape=Nutrition)) +
geom_point(size=1.5)
pca_out <- prcomp(t(assay(indata,"log_combat_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2,
Batch=indata$batch)
pca_plot %>% ggplot(aes(x=PC1, y=PC3, color=Batch, shape=Nutrition)) +
geom_point(size=1.5)
pca_out <- prcomp(t(assay(indata,"log_combat_cpm")))
pca_plot <- data.frame(pca_out$x, Disease=indata$Tb_status,
Nutrition=indata$bmi_cat2,
Batch=indata$batch)
pca_plot %>% ggplot(aes(x=PC1, y=PC3, color=Disease, shape=Nutrition)) +
geom_point(size=1.5)
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:500],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
cvfit.mal <- cv.glmnet(test, test.labels, family = "binomial",
type.measure = "class")
y_hat.mal <- as.factor(predict(cvfit.mal, test, s = "lambda.min", type = "class"))
confusionMatrix(y_hat.mal, test.labels)$overall["Accuracy"]
## Elastic Net
library(glmnet)
library(caret)
## using the most signifcant 100 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:100],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## svm
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:100],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
## using the most signifcant 100 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:500],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## svm
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:100],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:100],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
predict(cvfit, test, s = "lambda.min", type = "class")
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:500],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
### Random Forest
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
## using the most signifcant 100 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:1000],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
plot(nodesize, acc)
rf <- randomForest(train.labels ~ ., data = train.plus.label,
nodesize = nodesize[which.max(acc)])
y_hat <- as.factor(predict(rf, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
test <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:1000],
indata$bmi_cat2=="mal"])
test.labels <- indata$Tb_status[indata$bmi_cat2=="mal"]
test.plus.labels <- data.frame(test.labels,test)
### Elastic net
y_hat <- as.factor(predict(cvfit, test, s = "lambda.min", type = "class"))
en.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
en.test
y_hat <- as.factor(predict(svmfit, test.plus.labels[,-1], type = "class"))
svm.test <-confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
svm.test
y_hat <- as.factor(predict(rf, test.plus.labels[,-1], type = "class"))
rf.test <- confusionMatrix(y_hat, test.labels)$overall["Accuracy"]
rf.test
## Elastic Net
library(glmnet)
library(caret)
## using the most signifcant 100 genes from DESeq2
train <- t(as.matrix(assay(indata,"log_combat_cpm"))[
order(results(dds)[,6])[1:5000],
indata$bmi_cat2=="well"])
train.labels <- indata$Tb_status[indata$bmi_cat2=="well"]
cvfit <- cv.glmnet(train, train.labels, family = "binomial",
type.measure = "class")
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
y_hat <- as.factor(predict(cvfit, train, s = "lambda.min", type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## svm
library(e1071)
train.plus.label <- data.frame(train.labels, train)
svmfit <- svm(train.labels ~ ., data = train.plus.label, kernel = "linear", cost = 10, scale = FALSE)
y_hat <- as.factor(predict(svmfit, train.plus.label[,-1], type = "class"))
confusionMatrix(y_hat, train.labels)$overall["Accuracy"]
## Random Forest
library(randomForest)
nodesize <- seq(1, 51, 10)
acc <- sapply(nodesize, function(ns){
train(train.labels ~ ., method = "rf", data = train.plus.label,
tuneGrid = data.frame(mtry = 2),
nodesize = ns)$results$Accuracy })
results(dds)[,6]
View(results(dds))
View(as.matrix(results(dds)))
ssgsea_res <- runTBsigProfiler(indata,
useAssay = "log_counts_cpm",
algorithm = "ssGSEA",
combineSigAndAlgorithm = TRUE,
parallel.sz = 1)
library(TBSignatureProfiler)
ssgsea_res <- runTBsigProfiler(indata,
useAssay = "log_counts_cpm",
algorithm = "ssGSEA",
combineSigAndAlgorithm = TRUE,
parallel.sz = 1)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsignatures),
annotationColNames = c("Disease"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
names(TBsignatures)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsignatures),
annotationColNames = c("Disease"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
TBsigs <- TBsignatures[-12]
ssgsea_res <- runTBsigProfiler(indata,
useAssay = "log_counts_cpm",
signatures = TBsigs,
algorithm = "ssGSEA",
combineSigAndAlgorithm = TRUE,
parallel.sz = 1)
TBsigs <- TBsignatures[-12]
ssgsea_res <- runTBsigProfiler(indata,
useAssay = "log_counts_cpm",
signatures = TBsigs,
algorithm = "ssGSEA",
combineSigAndAlgorithm = TRUE,
parallel.sz = 1)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsigs),
annotationColNames = c("Disease"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsigs),
annotationColNames = c("Tb_staus"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsigs),
annotationColNames = c("Tb_status"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
signatureHeatmap(ssgsea_res,
name = "Heatmap of Signatures (ssGSEA)",
signatureColNames = names(TBsigs),
annotationColNames = c("Tb_status"),
scale = TRUE,
split_heatmap = "none",
showColumnNames = FALSE)
signatureBoxplot(ssgsea_res, name="ssGSEA",
signatureColNames = names(TBsigs)[c(62,77)],
annotationColName = c("Disease"))
signatureBoxplot(ssgsea_res, name="ssGSEA",
signatureColNames = names(TBsigs)[c(62,77)],
annotationColName = c("Tb_status"))
```
names(TBsigs)
signatureBoxplot(ssgsea_res, name="ssGSEA",
signatureColNames = c("Sweeney_OD_3","Zak_RISK_16"),
annotationColName = c("Tb_status"))
